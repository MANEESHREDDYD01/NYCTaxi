{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a47fbd-54a0-4303-9930-bec21ee4af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b02256-6f46-482a-aca7-58f371706d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848c04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62dbc040-c179-4893-8bca-7c556d757394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download raw data from 2023 to 2024\n",
      "File already exists for 2023-01.\n",
      "Loading data for 2023-01...\n",
      "Total records: 3,066,766\n",
      "Valid records: 2,993,140\n",
      "Records dropped: 73,626 (2.40%)\n",
      "Successfully processed data for 2023-01.\n",
      "File already exists for 2023-02.\n",
      "Loading data for 2023-02...\n",
      "Total records: 2,913,955\n",
      "Valid records: 2,845,058\n",
      "Records dropped: 68,897 (2.36%)\n",
      "Successfully processed data for 2023-02.\n",
      "File already exists for 2023-03.\n",
      "Loading data for 2023-03...\n",
      "Total records: 3,403,766\n",
      "Valid records: 3,331,705\n",
      "Records dropped: 72,061 (2.12%)\n",
      "Successfully processed data for 2023-03.\n",
      "File already exists for 2023-04.\n",
      "Loading data for 2023-04...\n",
      "Total records: 3,288,250\n",
      "Valid records: 3,214,922\n",
      "Records dropped: 73,328 (2.23%)\n",
      "Successfully processed data for 2023-04.\n",
      "File already exists for 2023-05.\n",
      "Loading data for 2023-05...\n",
      "Total records: 3,513,649\n",
      "Valid records: 3,435,875\n",
      "Records dropped: 77,774 (2.21%)\n",
      "Successfully processed data for 2023-05.\n",
      "File already exists for 2023-06.\n",
      "Loading data for 2023-06...\n",
      "Total records: 3,307,234\n",
      "Valid records: 3,233,969\n",
      "Records dropped: 73,265 (2.22%)\n",
      "Successfully processed data for 2023-06.\n",
      "File already exists for 2023-07.\n",
      "Loading data for 2023-07...\n",
      "Total records: 2,907,108\n",
      "Valid records: 2,838,637\n",
      "Records dropped: 68,471 (2.36%)\n",
      "Successfully processed data for 2023-07.\n",
      "File already exists for 2023-08.\n",
      "Loading data for 2023-08...\n",
      "Total records: 2,824,209\n",
      "Valid records: 2,758,739\n",
      "Records dropped: 65,470 (2.32%)\n",
      "Successfully processed data for 2023-08.\n",
      "File already exists for 2023-09.\n",
      "Loading data for 2023-09...\n",
      "Total records: 2,846,722\n",
      "Valid records: 2,782,920\n",
      "Records dropped: 63,802 (2.24%)\n",
      "Successfully processed data for 2023-09.\n",
      "File already exists for 2023-10.\n",
      "Loading data for 2023-10...\n",
      "Total records: 3,522,285\n",
      "Valid records: 3,446,406\n",
      "Records dropped: 75,879 (2.15%)\n",
      "Successfully processed data for 2023-10.\n",
      "File already exists for 2023-11.\n",
      "Loading data for 2023-11...\n",
      "Total records: 3,339,715\n",
      "Valid records: 3,267,940\n",
      "Records dropped: 71,775 (2.15%)\n",
      "Successfully processed data for 2023-11.\n",
      "File already exists for 2023-12.\n",
      "Loading data for 2023-12...\n",
      "Total records: 3,376,567\n",
      "Valid records: 3,313,957\n",
      "Records dropped: 62,610 (1.85%)\n",
      "Successfully processed data for 2023-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "from_year = 2023\n",
    "# to_year = datetime.now().year\n",
    "to_year = 2024\n",
    "print(f\"Download raw data from {from_year} to {to_year}\")\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "chunks = []\n",
    "for year in range(from_year, to_year+1):\n",
    "\n",
    "    rides_one_year = load_and_process_taxi_data(year)\n",
    "\n",
    "    chunks.append(rides_one_year)\n",
    "    break\n",
    "\n",
    "# Concatenate all chunks at the end\n",
    "rides = pd.concat(chunks, ignore_index=True)\n",
    "print(\"Data loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5589a2-9316-4dac-ba2e-e9a8a4789241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463263</th>\n",
       "      <td>2023-12-31 23:04:34</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463264</th>\n",
       "      <td>2023-12-31 23:08:15</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463265</th>\n",
       "      <td>2023-12-31 23:16:15</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463266</th>\n",
       "      <td>2023-12-31 23:21:58</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463267</th>\n",
       "      <td>2023-12-31 23:10:47</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37463268 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime  pickup_location_id\n",
       "0        2023-01-01 00:32:10                 161\n",
       "1        2023-01-01 00:55:08                  43\n",
       "2        2023-01-01 00:25:04                  48\n",
       "3        2023-01-01 00:03:48                 138\n",
       "4        2023-01-01 00:10:29                 107\n",
       "...                      ...                 ...\n",
       "37463263 2023-12-31 23:04:34                 233\n",
       "37463264 2023-12-31 23:08:15                  48\n",
       "37463265 2023-12-31 23:16:15                 196\n",
       "37463266 2023-12-31 23:21:58                 140\n",
       "37463267 2023-12-31 23:10:47                 237\n",
       "\n",
       "[37463268 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "515d0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Unique years in rides dataset:\", rides[\"pickup_datetime\"].dt.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f47e90-0fcb-4b7a-80d0-a68c979f9ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37463268, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5259f4bd-65ce-43dc-b487-09ee12d964bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59252b5f-17fc-4207-a1c4-6bebd49233ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277600, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92402d0c-dacd-4039-ba40-caf7eeafe8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2277600 entries, 0 to 2277599\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   pickup_location_id  int16         \n",
      " 2   rides               int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 26.1 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3804e864-fcde-41f4-bf92-5c0e8e90aa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277595</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277596</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277597</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277598</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277599</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2277600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_hour  pickup_location_id  rides\n",
       "0       2023-01-01 00:00:00                   2      0\n",
       "1       2023-01-01 01:00:00                   2      0\n",
       "2       2023-01-01 02:00:00                   2      0\n",
       "3       2023-01-01 03:00:00                   2      0\n",
       "4       2023-01-01 04:00:00                   2      0\n",
       "...                     ...                 ...    ...\n",
       "2277595 2023-12-31 19:00:00                 263    188\n",
       "2277596 2023-12-31 20:00:00                 263    198\n",
       "2277597 2023-12-31 21:00:00                 263    232\n",
       "2277598 2023-12-31 22:00:00                 263    160\n",
       "2277599 2023-12-31 23:00:00                 263     95\n",
       "\n",
       "[2277600 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50518b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hopsworks==4.1.5 hopsworks-aiomysql==0.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15fdf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['c:\\\\ProgramData\\\\anaconda3\\\\python.exe', '-m', 'pip', 'install', '--upgrade', 'hsfs', 'hopsworks', 'protobuf'], returncode=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Upgrade related dependencies\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"hsfs\", \"hopsworks\", \"protobuf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ef2515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env file has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import set_key, find_dotenv\n",
    "import os\n",
    "\n",
    "# Define the .env file path\n",
    "env_path = \".env\"\n",
    "\n",
    "# Define the key-value pairs to store in .env\n",
    "env_variables = {\n",
    "    \"HOPSWORKS_API_KEY\": \"qs8C3M2bboLcD6al.Y7SxCMMuXRyNknvXQeq3VcpBnaAC9yDnw3c6Kac8nEydkdPevkz412XSSgkNF8mh\",\n",
    "    \"PROJECT_ID_NAME\": \"taxidata\"\n",
    "}\n",
    "\n",
    "# Create and write to .env file\n",
    "with open(env_path, \"w\") as env_file:\n",
    "    for key, value in env_variables.items():\n",
    "        env_file.write(f\"{key}={value}\\n\")\n",
    "\n",
    "print(\".env file has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31ae5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hopsworks\n",
    "\n",
    "# # Use the API key for login\n",
    "# connection = hopsworks.connection(api_key_value=\"qs8C3M2bboLcD6al.Y7SxCMMuXRyNknvXQeq3VcpBnaAC9yDnw3c6Kac8nEydkdPevkz412XSSgkNF8mh\")\n",
    "\n",
    "# # Get your project\n",
    "# project = connection.get_project(\"taxidata\")\n",
    "\n",
    "# # Access the feature store of the project\n",
    "# feature_store = project.get_feature_store()\n",
    "\n",
    "# print(\"Connected to the Hopsworks project 'taxidata' successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f83e934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 03:32:59,854 INFO: Initializing external client\n",
      "2025-03-04 03:32:59,854 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 03:33:00,874 INFO: Python Engine initialized.\n",
      "Connected to the Hopsworks project: taxidata\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# The correct host URL with port included\n",
    "host = \"c.app.hopsworks.ai\"  # Without https:// and port\n",
    "port = 443  # Specify port as 443 explicitly\n",
    "\n",
    "# Your API key\n",
    "api_key = \"qs8C3M2bboLcD6al.Y7SxCMMuXRyNknvXQeq3VcpBnaAC9yDnw3c6Kac8nEydkdPevkz412XSSgkNF8mh\"\n",
    "\n",
    "# Establish connection to Hopsworks\n",
    "connection = hopsworks.connection(host=host, port=port, api_key_value=api_key)\n",
    "\n",
    "# Get the \"taxidata\" project\n",
    "project = connection.get_project(\"taxidata\")\n",
    "\n",
    "# Access the feature store of the project\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "print(f\"Connected to the Hopsworks project: {project.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8949a20a-f5da-45ff-990f-d789d234cdf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import hopsworks\n",
    "\n",
    "# api_key = os.getenv('HOPSWORKS_API_KEY')  \n",
    "# project_name = os.getenv('HOPSWORKS_PROJECT_NAME')  \n",
    "\n",
    "# #pip install confluent-kafka\n",
    "# #Initialize connection to Hopsworks  \n",
    "# project = hopsworks.login(  \n",
    "#     api_key_value=api_key,  \n",
    "#     project=project_name  \n",
    "# )  \n",
    "# print(f\"Successfully connected to Hopsworks project: {project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105841af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hopsworks \n",
    "# project = hopsworks.login()\n",
    "# fs = project.get_feature_store(name='taxidata_featurestore')\n",
    "# fg = fs.get_feature_group('time_series_hourly_feature_group', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a720ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have the project and feature store initialized\n",
    "# feature_store = project.get_feature_store()\n",
    "\n",
    "# # Get the feature group by name and version\n",
    "# feature_group = feature_store.get_feature_group(FEATURE_GROUP_NAME, FEATURE_GROUP_VERSION)\n",
    "\n",
    "# # Delete the feature group\n",
    "# feature_group.delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "348b1a4b-6141-4078-bc9f-e9e3a750a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d54682e-b7d3-49fc-86bd-65b1b06206bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794e0dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created successfully!\n"
     ]
    }
   ],
   "source": [
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Create the feature group\n",
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group for hourly time series data\",\n",
    "    primary_key=[\"timestamp\"],  # Adjust primary key according to your dataset\n",
    "    online_enabled=True\n",
    ")\n",
    "print(\"Feature group created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4277696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Create a DataFrame with hourly data\n",
    "# date_range = pd.date_range(start=\"2024-01-01\", periods=100, freq='H')\n",
    "# df = pd.DataFrame({\n",
    "#     \"timestamp\": date_range,\n",
    "#     \"ride_count\": np.random.randint(5, 100, size=len(date_range)),\n",
    "#     \"day_of_week\": date_range.dayofweek,\n",
    "#     \"hour\": date_range.hour,\n",
    "#     \"is_weekend\": (date_range.dayofweek >= 5).astype(int),\n",
    "#     \"temperature\": np.random.uniform(10, 30, size=len(date_range)),\n",
    "#     \"precipitation\": np.random.uniform(0, 10, size=len(date_range)),\n",
    "#     \"pickup_location\": np.random.choice([1, 2, 3, 4, 5], size=len(date_range)),\n",
    "#     \"event_holiday\": np.random.choice([0, 1], size=len(date_range))\n",
    "# })\n",
    "\n",
    "# # Create a new unique identifier column (e.g., an integer index)\n",
    "# df[\"id\"] = range(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e95a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Create a DataFrame with hourly data\n",
    "# date_range = pd.date_range(start=\"2024-01-01\", periods=100, freq='H')\n",
    "# df = pd.DataFrame({\n",
    "#     \"timestamp\": date_range,\n",
    "#     \"ride_count\": np.random.randint(5, 100, size=len(date_range)),\n",
    "#     \"day_of_week\": date_range.dayofweek,\n",
    "#     \"hour\": date_range.hour,\n",
    "#     \"is_weekend\": (date_range.dayofweek >= 5).astype(int),\n",
    "#     \"temperature\": np.random.uniform(10, 30, size=len(date_range)),\n",
    "#     \"precipitation\": np.random.uniform(0, 10, size=len(date_range)),\n",
    "#     \"pickup_location\": np.random.choice([1, 2, 3, 4, 5], size=len(date_range)),\n",
    "#     \"event_holiday\": np.random.choice([0, 1], size=len(date_range))\n",
    "# })\n",
    "\n",
    "# # Drop the unnecessary columns permanently\n",
    "# df.drop(columns=['day_of_week', 'hour', 'is_weekend', 'temperature', 'precipitation', \n",
    "#                  'event_holiday'], inplace=True)\n",
    "\n",
    "# # Rename columns to match your required names (if necessary)\n",
    "# df.rename(columns={\n",
    "#     'timestamp': 'pickup_hour',\n",
    "#     'pickup_location': 'pickup_location_id',\n",
    "#     'ride_count': 'rides'\n",
    "# }, inplace=True)\n",
    "\n",
    "# # Now, df will have the required columns: pickup_hour, pickup_location_id, and rides\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "951b430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created with supported primary key for online serving.\n"
     ]
    }
   ],
   "source": [
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group for hourly time series data\",  # Use the new 'id' column as the primary key\n",
    "    online_enabled=True   # Enable online serving if needed\n",
    ")\n",
    "print(\"Feature group created with supported primary key for online serving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de327ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_group = feature_store.get_or_create_feature_group(\n",
    "# name=config.FEATURE_GROUP_NAME,\n",
    "# version=config.FEATURE_GROUP_VERSION,\n",
    "# description=\"Time series data at hourly frequency\",\n",
    "# primary_key=['pickup_location_id','pickup_hour'],\n",
    "# event_time = ['pickup_hour']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c976a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error inserting data: module 'hsfs.feature_group' has no attribute 'insert'\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary imports\n",
    "from hsfs import feature_group\n",
    "\n",
    "# Assuming 'df' is your pandas DataFrame\n",
    "try:\n",
    "    feature_group.insert(df)\n",
    "    print(\"Data inserted into the feature group.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96fcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hsfs.feature_group import FeatureGroup\n",
    "# from hsfs.feature import Feature\n",
    "\n",
    "# # Assuming you have the project and feature store initialized\n",
    "# feature_store = project.get_feature_store()\n",
    "# featurestore_id = feature_store.id  # Get the feature store ID\n",
    "\n",
    "# # Define features using Feature objects\n",
    "# pickup_hour = Feature(name=\"pickup_hour\", dtype=\"timestamp\")\n",
    "# pickup_location_id = Feature(name=\"pickup_location_id\", dtype=\"int\")\n",
    "# rides = Feature(name=\"rides\", dtype=\"int\")\n",
    "\n",
    "# # Specify the primary key (for example, using 'pickup_hour')\n",
    "# primary_key = [\"pickup_hour\"]\n",
    "\n",
    "# # Create the feature group with the required feature store ID, features, and primary key\n",
    "# feature_group = FeatureGroup(\n",
    "#     name=FEATURE_GROUP_NAME,\n",
    "#     version=FEATURE_GROUP_VERSION,\n",
    "#     featurestore_id=featurestore_id,  # Provide the feature store ID\n",
    "#     description=\"Time Series Hourly Feature Group for rides data\",\n",
    "#     online_enabled=True,  # Set to False if you don't need online serving\n",
    "#     features=[pickup_hour, pickup_location_id, rides],  # Pass features here\n",
    "#     primary_key=primary_key  # Provide the primary key\n",
    "# )\n",
    "\n",
    "# # Save the feature group to finalize its creation\n",
    "# feature_group.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15447369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_group = feature_store.get_feature_group(\n",
    "#     name=FEATURE_GROUP_NAME,\n",
    "#     version=FEATURE_GROUP_VERSION,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b9421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"id\" not in ts_data.columns:\n",
    "#     ts_data['id'] = range(1, len(ts_data) + 1)  # Create an 'id' column if it's missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3dd702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.rename(columns={\n",
    "    'pickup_hour': 'pickup_hour',\n",
    "    'pickup_location_id': 'pickup_location_id',\n",
    "    'rides': 'rides'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a967b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'])\n",
    "ts_data['pickup_location_id'] = ts_data['pickup_location_id'].astype(int)\n",
    "ts_data['rides'] = ts_data['rides'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "785c6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    description=\"Time series data at hourly frequency\",\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "    event_time=['pickup_hour']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e0ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.rename(columns={\n",
    "    \"pickup_hour\": \"timestamp\",\n",
    "    \"rides\": \"ride_count\",\n",
    "    \"pickup_location_id\": \"pickup_location\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "549705b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define default values for missing columns\n",
    "# ts_data[\"day_of_week\"] = pd.to_datetime(ts_data[\"timestamp\"]).dt.dayofweek  # Extract from timestamp\n",
    "# ts_data[\"hour\"] = pd.to_datetime(ts_data[\"timestamp\"]).dt.hour  # Extract hour\n",
    "# ts_data[\"is_weekend\"] = ts_data[\"day_of_week\"].apply(lambda x: 1 if x >= 5 else 0)  # 1 for Sat/Sun\n",
    "# ts_data[\"temperature\"] = 20.0  # Default temperature (replace with actual data)\n",
    "# ts_data[\"precipitation\"] = 0.0  # Default precipitation (replace with actual data)\n",
    "# ts_data[\"event_holiday\"] = 0  # Default no holiday\n",
    "\n",
    "# # Ensure 'id' is unique\n",
    "# ts_data[\"id\"] = range(1, len(ts_data) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a939492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp          datetime64[ns]\n",
      "pickup_location             int32\n",
      "ride_count                  int32\n",
      "dtype: object\n",
      "            timestamp  pickup_location  ride_count\n",
      "0 2023-01-01 00:00:00                2           0\n",
      "1 2023-01-01 01:00:00                2           0\n",
      "2 2023-01-01 02:00:00                2           0\n",
      "3 2023-01-01 03:00:00                2           0\n",
      "4 2023-01-01 04:00:00                2           0\n"
     ]
    }
   ],
   "source": [
    "print(ts_data.dtypes)  # Check data types\n",
    "print(ts_data.head())  # Preview data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01a85e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ts_data[\"id\"].is_unique)  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4df00a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_data[\"is_weekend\"] = ts_data[\"is_weekend\"].astype(\"int32\")\n",
    "# ts_data[\"event_holiday\"] = ts_data[\"event_holiday\"].astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaad150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install confluent-kafka\n",
    "# from confluent_kafka import Producer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425eb22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'pickup_location', 'ride_count'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ts_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab0c6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ts_data_selected.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bde6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 2277600/2277600 | Elapsed Time: 02:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1215644/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "ts_data.rename(columns={\n",
    "    'timestamp': 'pickup_hour',\n",
    "    'pickup_location': 'pickup_location_id',\n",
    "    'ride_count': 'rides'\n",
    "}, inplace=True)\n",
    "\n",
    "# Select only the required columns\n",
    "ts_data_selected = ts_data[['pickup_hour', 'pickup_location_id', 'rides']]\n",
    "\n",
    "# Insert the selected columns into the feature group\n",
    "feature_group.insert(ts_data_selected, write_options={\"wait_for_job\": False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec573dd2-3125-4d2f-93a9-975bedfe739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from confluent_kafka import Producer\n",
    "# feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9ff98cc-31f4-47b4-a43c-fe731760af71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 857.47 MB\n"
     ]
    }
   ],
   "source": [
    "df_memory_mb = rides.memory_usage(deep=True).sum() / (1024 * 1024)  \n",
    "print(f\"DataFrame size: {df_memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be636b4b-4bd5-469d-8cc7-b09e1de29ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2277600 entries, 0 to 2277599\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   pickup_location_id  int32         \n",
      " 2   rides               int32         \n",
      "dtypes: datetime64[ns](1), int32(2)\n",
      "memory usage: 34.8 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
